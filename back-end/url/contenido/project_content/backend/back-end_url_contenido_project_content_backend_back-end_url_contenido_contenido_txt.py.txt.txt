# ARCHIVO: back-end/url/contenido/project_content/backend/back-end_url_contenido_contenido_txt.py.txt
# URL: https://raw.githubusercontent.com/sTr4yDev/speakLexi/main/back-end/url/contenido/project_content/backend/back-end_url_contenido_contenido_txt.py.txt
# FECHA DESCARGA: 2025-10-29 18:40:29
# ==================================================

# ARCHIVO: back-end/url/contenido/contenido_txt.py
# URL: https://raw.githubusercontent.com/sTr4yDev/speakLexi/main/back-end/url/contenido/contenido_txt.py
# FECHA DESCARGA: 2025-10-28 22:54:30
# ==================================================

# download_project_content.py
import requests
import os
import argparse
import json
from datetime import datetime
from colorama import Fore, Style, init
import time
import re

init(autoreset=True)

def sanitize_filename(filename):
    """Limpia el nombre de archivo para que sea v√°lido en sistemas de archivos"""
    return re.sub(r'[<>:"/\\|?*]', '_', filename)

def download_file_content(url, max_retries=3):
    """Descarga el contenido de un archivo con reintentos"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                return response.text
            elif response.status_code == 404:
                return f"# ERROR: Archivo no encontrado (404)\n# URL: {url}"
            elif response.status_code == 403:
                time.sleep(2)  # Esperar por rate limiting
                continue
            else:
                return f"# ERROR: C√≥digo {response.status_code}\n# URL: {url}"
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            return f"# ERROR: {str(e)}\n# URL: {url}"
    
    return f"# ERROR: Fallo despu√©s de {max_retries} intentos\n# URL: {url}"

def get_project_structure(user, repo, branch="main"):
    """Obtiene la estructura del proyecto desde GitHub API"""
    url = f"https://api.github.com/repos/{user}/{repo}/git/trees/{branch}?recursive=1"
    
    token = os.getenv("GITHUB_TOKEN")
    headers = {"Authorization": f"token {token}"} if token else {}
    
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"{Fore.RED}‚ùå Error {response.status_code} al acceder al repositorio.{Style.RESET_ALL}")
        return []
    
    return response.json().get('tree', [])

def download_project_content(user, repo, branch="main", output_dir="project_content"):
    """Descarga el contenido completo del proyecto"""
    
    # Crear directorio de salida
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Obtener estructura del proyecto
    tree = get_project_structure(user, repo, branch)
    if not tree:
        return
    
    # Patrones para ignorar
    ignore_patterns = [
        'node_modules/', '__pycache__/', '.next/', 'venv/', 'env/', '.git/',
        'dist/', 'build/', '.env', 'package-lock.json', 'yarn.lock',
        '.vercel/', 'out/', '.gitignore', '.DS_Store', 'thumbs.db',
        '*.pyc', '*.log', '*.tmp'
    ]
    
    # Extensiones de archivo a procesar
    text_extensions = {
        '.py', '.tsx', '.ts', '.jsx', '.js', '.css', '.md', '.txt', 
        '.json', '.yml', '.yaml', '.xml', '.html', '.htm', '.sql',
        '.sh', '.bat', '.ps1', '.config', '.toml', '.ini'
    }
    
    backend_files = []
    frontend_files = []
    docs_files = []
    other_files = []
    
    print(f"\nüîç Escaneando proyecto: {Fore.CYAN}{repo}{Style.RESET_ALL}")
    print(f"üìÅ Descargando contenido a: {output_dir}/\n")
    
    total_files = 0
    for item in tree:
        path = item['path']
        
        # Ignorar archivos no deseados
        if any(pattern in path for pattern in ignore_patterns):
            continue
        
        # Solo procesar archivos de texto
        file_ext = os.path.splitext(path)[1].lower()
        if file_ext not in text_extensions:
            continue
        
        total_files += 1
        raw_url = f"https://raw.githubusercontent.com/{user}/{repo}/{branch}/{path}"
        
        # Clasificar archivos
        if path.startswith('back-end/'):
            backend_files.append({'path': path, 'url': raw_url})
            print(f"{Fore.GREEN}üêç Backend:{Style.RESET_ALL} {path}")
        elif path.startswith('front-end/'):
            frontend_files.append({'path': path, 'url': raw_url})
            print(f"{Fore.MAGENTA}‚öõÔ∏è  Frontend:{Style.RESET_ALL} {path}")
        elif path.startswith('docs/'):
            docs_files.append({'path': path, 'url': raw_url})
            print(f"{Fore.CYAN}üìò Docs:{Style.RESET_ALL} {path}")
        else:
            other_files.append({'path': path, 'url': raw_url})
            print(f"{Fore.YELLOW}üìÑ Otros:{Style.RESET_ALL} {path}")
    
    print(f"\nüìä Total de archivos a descargar: {total_files}")
    
    # Descargar y guardar contenido
    download_and_save_files(backend_files, "backend", output_dir)
    download_and_save_files(frontend_files, "frontend", output_dir)
    download_and_save_files(docs_files, "docs", output_dir)
    download_and_save_files(other_files, "other", output_dir)
    
    # Crear archivos consolidados
    create_consolidated_files(backend_files, frontend_files, docs_files, other_files, output_dir)
    
    return {
        "backend": backend_files,
        "frontend": frontend_files,
        "docs": docs_files,
        "other": other_files
    }

def download_and_save_files(files, category, output_dir):
    """Descarga y guarda archivos de una categor√≠a espec√≠fica"""
    if not files:
        return
    
    category_dir = os.path.join(output_dir, category)
    if not os.path.exists(category_dir):
        os.makedirs(category_dir)
    
    print(f"\nüì• Descargando {len(files)} archivos de {category}...")
    
    for i, file_info in enumerate(files, 1):
        path = file_info['path']
        url = file_info['url']
        
        # Crear nombre de archivo seguro
        safe_filename = sanitize_filename(path.replace('/', '_')) + '.txt'
        file_path = os.path.join(category_dir, safe_filename)
        
        # Descargar contenido
        content = download_file_content(url)
        
        # Guardar con metadatos
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# ARCHIVO: {path}\n")
            f.write(f"# URL: {url}\n")
            f.write(f"# FECHA DESCARGA: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("# " + "=" * 50 + "\n\n")
            f.write(content)
        
        print(f"  [{i}/{len(files)}] ‚úÖ {safe_filename}")
        
        # Peque√±a pausa para no saturar GitHub
        time.sleep(0.1)

def create_consolidated_files(backend, frontend, docs, other, output_dir):
    """Crea archivos consolidados por categor√≠a"""
    print(f"\nüì¶ Creando archivos consolidados...")
    
    # Backend consolidado
    if backend:
        with open(os.path.join(output_dir, 'BACKEND_COMPLETO.txt'), 'w', encoding='utf-8') as f:
            f.write("# BACKEND COMPLETO - SpeakLexi\n")
            f.write(f"# Total archivos: {len(backend)}\n")
            f.write(f"# Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for file_info in backend:
                f.write(f"\n{'='*80}\n")
                f.write(f"# ARCHIVO: {file_info['path']}\n")
                f.write(f"# URL: {file_info['url']}\n")
                f.write(f"{'='*80}\n\n")
                content = download_file_content(file_info['url'])
                f.write(content)
                f.write("\n\n")
        print("  ‚úÖ BACKEND_COMPLETO.txt")
    
    # Frontend consolidado
    if frontend:
        with open(os.path.join(output_dir, 'FRONTEND_COMPLETO.txt'), 'w', encoding='utf-8') as f:
            f.write("# FRONTEND COMPLETO - SpeakLexi\n")
            f.write(f"# Total archivos: {len(frontend)}\n")
            f.write(f"# Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for file_info in frontend:
                f.write(f"\n{'='*80}\n")
                f.write(f"# ARCHIVO: {file_info['path']}\n")
                f.write(f"# URL: {file_info['url']}\n")
                f.write(f"{'='*80}\n\n")
                content = download_file_content(file_info['url'])
                f.write(content)
                f.write("\n\n")
        print("  ‚úÖ FRONTEND_COMPLETO.txt")
    
    # Proyecto completo
    all_files = backend + frontend + docs + other
    if all_files:
        with open(os.path.join(output_dir, 'PROYECTO_COMPLETO.txt'), 'w', encoding='utf-8') as f:
            f.write("# PROYECTO COMPLETO - SpeakLexi\n")
            f.write(f"# Backend: {len(backend)} archivos\n")
            f.write(f"# Frontend: {len(frontend)} archivos\n")
            f.write(f"# Docs: {len(docs)} archivos\n")
            f.write(f"# Otros: {len(other)} archivos\n")
            f.write(f"# Total: {len(all_files)} archivos\n")
            f.write(f"# Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for category, files in [
                ("BACKEND", backend),
                ("FRONTEND", frontend),
                ("DOCUMENTACI√ìN", docs),
                ("OTROS", other)
            ]:
                if files:
                    f.write(f"\n{'#'*80}\n")
                    f.write(f"# {category}\n")
                    f.write(f"{'#'*80}\n\n")
                    
                    for file_info in files:
                        f.write(f"\n{'='*80}\n")
                        f.write(f"# ARCHIVO: {file_info['path']}\n")
                        f.write(f"# URL: {file_info['url']}\n")
                        f.write(f"{'='*80}\n\n")
                        content = download_file_content(file_info['url'])
                        f.write(content)
                        f.write("\n\n")
        print("  ‚úÖ PROYECTO_COMPLETO.txt")
    
    # Metadata JSON
    metadata = {
        "project": "SpeakLexi",
        "backend_files": len(backend),
        "frontend_files": len(frontend),
        "docs_files": len(docs),
        "other_files": len(other),
        "total_files": len(all_files),
        "generated": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "files": {
            "backend": [f["path"] for f in backend],
            "frontend": [f["path"] for f in frontend],
            "docs": [f["path"] for f in docs],
            "other": [f["path"] for f in other]
        }
    }
    
    with open(os.path.join(output_dir, 'metadata.json'), 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    print("  ‚úÖ metadata.json")

def main():
    parser = argparse.ArgumentParser(description="Descarga el contenido completo de un repositorio GitHub")
    parser.add_argument("user", help="Usuario o organizaci√≥n de GitHub")
    parser.add_argument("repo", help="Nombre del repositorio")
    parser.add_argument("--branch", default="main", help="Rama del repositorio")
    parser.add_argument("--output", default="project_content", help="Directorio de salida")
    
    args = parser.parse_args()
    
    start_time = time.time()
    
    try:
        result = download_project_content(
            args.user, 
            args.repo, 
            args.branch, 
            args.output
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"\n{'='*60}")
        print("üéâ DESCARGA COMPLETADA")
        print(f"{'='*60}")
        print(f"üìÅ Contenido guardado en: {args.output}/")
        print(f"‚è±Ô∏è  Tiempo total: {duration:.2f} segundos")
        print(f"üìä Archivos descargados:")
        print(f"   üêç Backend: {len(result['backend'])} archivos")
        print(f"   ‚öõÔ∏è  Frontend: {len(result['frontend'])} archivos")
        print(f"   üìò Docs: {len(result['docs'])} archivos")
        print(f"   üìÑ Otros: {len(result['other'])} archivos")
        print(f"   üì¶ Total: {sum(len(v) for v in result.values())} archivos")
        print(f"\nüìã Archivos generados:")
        print(f"   üìÑ PROYECTO_COMPLETO.txt - Todo el c√≥digo en un archivo")
        print(f"   üìÑ BACKEND_COMPLETO.txt  - Solo backend")
        print(f"   üìÑ FRONTEND_COMPLETO.txt - Solo frontend")
        print(f"   üìÅ {args.output}/backend/  - Archivos individuales backend")
        print(f"   üìÅ {args.output}/frontend/ - Archivos individuales frontend")
        print(f"   üìÅ {args.output}/docs/     - Archivos individuales docs")
        print(f"   üìÑ metadata.json - Metadatos del proyecto")
        print(f"\nüí° Ahora puedes compartir los .txt con cualquier IA")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"{Fore.RED}‚ùå Error durante la descarga: {str(e)}{Style.RESET_ALL}")

if __name__ == "__main__":
    main()